{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/n1c0e/Operations_Management-Gestion_de_operaciones-ICS3213/blob/main/Proyecto_IIC2433_Data_Mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1rBnq_mMLUu"
      },
      "source": [
        "Pontificia Universidad Católica de Chile <br>\n",
        "Departamento de Ciencia de la Computación <br>\n",
        "IIC2433 - Minería de Datos\n",
        "<br>\n",
        "\n",
        "<center>\n",
        "    <h2> Entrega 3 </h2>\n",
        "    <p>\n",
        "        Profesor Marcelo Mendoza<br>\n",
        "        Segundo Semestre 2022<br>    \n",
        "    </p>\n",
        "    <br>\n",
        "</center>\n",
        "\n",
        "<br>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n"
      ],
      "metadata": {
        "id": "SbAjtaxQSyU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip3 uninstall spacy\n",
        "!pip3 install spacy\n",
        "\n",
        "!spacy download en_core_web_lg\n",
        "clear_output()\n",
        "print('Ahora debes reiniciar el entorno de ejecución y ejecutar a partir de la siguiente celda')"
      ],
      "metadata": {
        "id": "7MwOI68iSxzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2886868-434e-4882-958d-7ab483609149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ahora debes reiniciar el entorno de ejecución y ejecutar a partir de la siguiente celda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import spacy\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier as RFC\n",
        "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn import metrics\n",
        "from sklearn.tree import DecisionTreeClassifier as DTC\n",
        "import itertools\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb"
      ],
      "metadata": {
        "id": "-T1Dy2hKSwdZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9109f7-e580-4919-dc93-f570689eb829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")"
      ],
      "metadata": {
        "id": "HhOI_bandiPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importar dataset"
      ],
      "metadata": {
        "id": "dHbdD91DMP7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train_url = \"/content/train.dat\"\n",
        "data_test_url = \"/content/test.dat\"\n",
        "\n",
        "DATA_TRAIN = pd.read_csv(data_train_url, sep='\t', header=None, names=['label', 'abstract'])\n",
        "DATA_TEST = pd.read_csv(data_test_url, sep='\t', header=None, names=['abstract'])\n",
        "DATA_TRAIN.head()"
      ],
      "metadata": {
        "id": "O5TZNy00SpJ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "e5db8bd1-e2b8-4ff9-a451-afde69ac7a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1a65c5e20415>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_test_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/test.dat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mDATA_TRAIN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'  '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'abstract'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mDATA_TEST\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'    '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'abstract'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mDATA_TRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/train.dat'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_TEST.head()"
      ],
      "metadata": {
        "id": "WD6W-aOZUyG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesamiento de datos"
      ],
      "metadata": {
        "id": "GeqNreADMS0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funciones dadas la tarea 2\n",
        "import string\n",
        "\n",
        "all_stopwords = nlp.Defaults.stop_words\n",
        "\n",
        "def remove_punctuation(text):\n",
        "  text = [token for token in text if not token.is_punct]\n",
        "  return text\n",
        "\n",
        "def remove_stopwords(words):\n",
        "  words = [word for word in words if not word in all_stopwords]\n",
        "  return words\n",
        "\n",
        "def lemmatize(words):\n",
        "  words = [word.lemma_ for word in words]\n",
        "  return words\n",
        "\n",
        "def remove_non_alpha(words):\n",
        "  words = [word for word in words if word.isalpha()]\n",
        "  return words\n",
        "\n",
        "def lower(words):\n",
        "  words = [word.lower() for word in words]\n",
        "  return words\n",
        "\n",
        "def preprocess(text):\n",
        "\n",
        "  doc = nlp(text)\n",
        "  tokens = remove_punctuation(doc)\n",
        "  tokens = remove_stopwords(tokens)\n",
        "  tokens = lemmatize(tokens)\n",
        "  tokens = remove_non_alpha(tokens)\n",
        "  tokens = lower(tokens)\n",
        "\n",
        "  return ' '.join(tokens).strip()\n",
        "\n",
        "\n",
        "def sentence_vector(text):\n",
        "  text = nlp(text)\n",
        "  vectores = []\n",
        "  for t in text:\n",
        "    t_vector = t.vector\n",
        "    vectores.append(t_vector)\n",
        "  return np.array(vectores).sum(axis=0)/len(vectores)"
      ],
      "metadata": {
        "id": "fUbQ87H6MWQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizar train data"
      ],
      "metadata": {
        "id": "TnASLDJ0YD-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train = DATA_TRAIN.copy().drop(df_train.index[500:])\n",
        "df_train = DATA_TRAIN.copy().sample(n=750)\n",
        "df_train"
      ],
      "metadata": {
        "id": "j_2uI-k0WSq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['abstract'] = df_train['abstract'].apply(preprocess)\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "WeMqYpUmXmYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['abstract'] = df_train['abstract'].apply(sentence_vector)"
      ],
      "metadata": {
        "id": "ee6gGFqEX9zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorizar test data"
      ],
      "metadata": {
        "id": "DCC23xZ7YHvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_test = DATA_TEST.copy().drop(df_test.index[50:])\n",
        "# df_test['abstract'] = df_test['abstract'].apply(preprocess)\n",
        "# df_test['abstract'] = df_test['abstract'].apply(sentence_vector)\n",
        "# df_test.head()"
      ],
      "metadata": {
        "id": "KWUNEGRtYB--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dividir DATA en sets de train y de test aplicar PCA\n",
        "\n",
        "Como solo data_train viene con labels, dividiremos este dataset en sets de train y de test con la función `train_test_split` de sklearn.model_selection.\n",
        "\n"
      ],
      "metadata": {
        "id": "xNAhuFq7ZHds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realiza aquí la separación balanceada en train y test\n",
        "X = df_train['abstract']\n",
        "y = df_train['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=10)"
      ],
      "metadata": {
        "id": "3JPvxV7CZHGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "LuD_mua-dchE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [i.tolist() for i in X_train.to_numpy()]\n",
        "X_test = [i.tolist() for i in X_test.to_numpy()]"
      ],
      "metadata": {
        "id": "5op9ppSEe-hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.to_numpy().tolist()"
      ],
      "metadata": {
        "id": "fKfw0nXFfJb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, se aplicará PCA para reducir el largo de los vectores retornados por NLP. Esto será una nueva data que se contrastará en la clasificaciones con la data original."
      ],
      "metadata": {
        "id": "7dMe-jSvSSlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_train = PCA(n_components=0.95, svd_solver='full')\n",
        "X_train_pca = pca_train.fit_transform(X_train)\n",
        "n_filas, n_columnas = X_train_pca.shape\n",
        "\n",
        "pca_test = PCA(n_components=n_columnas, svd_solver='full')\n",
        "X_test_pca = pca_test.fit_transform(X_test)\n",
        "print(len(X_train_pca[0]), len(X_test_pca[0]))"
      ],
      "metadata": {
        "id": "aLjc1uyIS6jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clasificador"
      ],
      "metadata": {
        "id": "E1-4WJZnMXDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear SVC"
      ],
      "metadata": {
        "id": "GGQKsQzFm9Nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_linearSVC = {'C': [0.1, 1.0, 3.0, 100.0],\\\n",
        "              'loss': ['hinge', 'squared_hinge'],\\\n",
        "              'penalty': ['l1', 'l2']\n",
        "              }\n",
        "\n",
        "grid_linearSVC = GridSearchCV(LinearSVC(), param_grid_linearSVC, refit=True)\n",
        "grid_linearSVC.fit(X_train, y_train)\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "hCxdfNoBpk_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linearSVC = LinearSVC().set_params(**grid_linearSVC.best_params_)\n",
        "linearSVC.fit(X_train, y_train)\n",
        "y_predict_linearSVC = linearSVC.predict(X_test)"
      ],
      "metadata": {
        "id": "Qnf6dgPnMbIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('hiperparámetros LinearSVC:', grid_linearSVC.best_params_)"
      ],
      "metadata": {
        "id": "7QUdeutU_s5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Matriz de confusión Linear SVC\")\n",
        "cm_linearSVC = confusion_matrix(y_test, y_predict_linearSVC, normalize=\"all\")\n",
        "cm_display = ConfusionMatrixDisplay(cm_linearSVC).plot(cmap='magma')"
      ],
      "metadata": {
        "id": "UXGX1hD-5huN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy LinearSVC = {metrics.accuracy_score(y_test, y_predict_linearSVC) * 100} %\")"
      ],
      "metadata": {
        "id": "INvRiJtbezvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear SVC (PCA)"
      ],
      "metadata": {
        "id": "IojzR36EXbVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_linearSVC = {'C': [0.1, 1.0, 3.0, 100.0],\\\n",
        "              'loss': ['hinge', 'squared_hinge'],\\\n",
        "              'penalty': ['l1', 'l2']\n",
        "              }\n",
        "\n",
        "grid_linearSVC = GridSearchCV(LinearSVC(), param_grid_linearSVC, refit=True)\n",
        "grid_linearSVC.fit(X_train_pca, y_train)\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "Fi_55ZMHXhZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linearSVC = LinearSVC().set_params(**grid_linearSVC.best_params_)\n",
        "linearSVC.fit(X_train_pca, y_train)\n",
        "y_predict_linearSVC = linearSVC.predict(X_test_pca)"
      ],
      "metadata": {
        "id": "cFW1ainLXkyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('hiperparámetros LinearSVC:', grid_linearSVC.best_params_)"
      ],
      "metadata": {
        "id": "eCUY-ONaXnVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Matriz de confusión Linear SVC\")\n",
        "cm_linearSVC = confusion_matrix(y_test, y_predict_linearSVC, normalize=\"all\")\n",
        "cm_display = ConfusionMatrixDisplay(cm_linearSVC).plot(cmap='magma')"
      ],
      "metadata": {
        "id": "nFrK4Uu0XpSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy LinearSVC = {metrics.accuracy_score(y_test, y_predict_linearSVC) * 100} %\")"
      ],
      "metadata": {
        "id": "b_aUmhO8XrtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVC\n"
      ],
      "metadata": {
        "id": "Z6UIZCQAiiTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_svc = {'C': [0.1,1, 10, 100],\\\n",
        "                  'gamma': [1,0.1,0.01,0.001],\\\n",
        "                  'kernel': ['rbf', 'poly', 'sigmoid']\\\n",
        "                  }\n",
        "\n",
        "grid_svc = GridSearchCV(SVC(), param_grid_svc, refit=True)\n",
        "grid_svc.fit(X_train, y_train)\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "SFTt4mxtqWlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc = SVC().set_params(**grid_svc.best_params_)\n",
        "svc.fit(X_train, y_train)\n",
        "y_predict_SVC = svc.predict(X_test)"
      ],
      "metadata": {
        "id": "GSsrD3NdqZJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('hiperparámetros SVC:', grid_svc.best_params_)"
      ],
      "metadata": {
        "id": "yxArkIRx_1RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Matriz de confusión SVC\")\n",
        "cm_SVC = confusion_matrix(y_test, y_predict_SVC, normalize=\"all\")\n",
        "cm_display = ConfusionMatrixDisplay(cm_SVC).plot(cmap='magma')"
      ],
      "metadata": {
        "id": "x5NHIR7Hqasy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy SVC = {metrics.accuracy_score(y_test, y_predict_SVC) * 100} %\")"
      ],
      "metadata": {
        "id": "6HlnsSJIqcF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVC (PCA)"
      ],
      "metadata": {
        "id": "qWZblSHHgL9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_svc = {'C': [0.1,1, 10, 100],\\\n",
        "                  'gamma': [1,0.1,0.01,0.001],\\\n",
        "                  'kernel': ['rbf', 'poly', 'sigmoid']\\\n",
        "                  }\n",
        "\n",
        "grid_svc = GridSearchCV(SVC(), param_grid_svc, refit=True)\n",
        "grid_svc.fit(X_train_pca, y_train)\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "lPLLh7LIgNsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svc = SVC().set_params(**grid_svc.best_params_)\n",
        "svc.fit(X_train_pca, y_train)\n",
        "y_predict_SVC = svc.predict(X_test_pca)"
      ],
      "metadata": {
        "id": "SBnwcHGJgaCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('hiperparámetros SVC:', grid_svc.best_params_)"
      ],
      "metadata": {
        "id": "GXrk1SHEgcCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Matriz de confusión SVC\")\n",
        "cm_SVC = confusion_matrix(y_test, y_predict_SVC, normalize=\"all\")\n",
        "cm_display = ConfusionMatrixDisplay(cm_SVC).plot(cmap='magma')"
      ],
      "metadata": {
        "id": "gqK718lxgeoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy SVC = {metrics.accuracy_score(y_test, y_predict_SVC) * 100} %\")"
      ],
      "metadata": {
        "id": "Oc-z13iNggw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PCA disminuye el accuracy. Mejor no utilizar.**"
      ],
      "metadata": {
        "id": "RZOP242qDcE4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "Jv_L39J8_o03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_rfc = {'n_estimators': [10, 100, 500, 1000],\\\n",
        "                  'criterion': ['gini', 'entropy', 'log_loss']\n",
        "                  }\n",
        "\n",
        "grid_rfc = GridSearchCV(RFC(), param_grid_rfc, refit=True)\n",
        "grid_rfc.fit(X_train, y_train)\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "Lsv6EvOplEvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RFC().set_params(**grid_rfc.best_params_)\n",
        "rfc.fit(X_train, y_train)\n",
        "y_predict_rfc = rfc.predict(X_test)"
      ],
      "metadata": {
        "id": "BRXC4BuE_tRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('hiperparámetros RFC:', grid_rfc.best_params_)"
      ],
      "metadata": {
        "id": "8luXD0v1mOln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Matriz de confusión RFC\")\n",
        "cm_RFC = confusion_matrix(y_test, y_predict_rfc, normalize=\"all\")\n",
        "cm_display = ConfusionMatrixDisplay(cm_RFC).plot(cmap='magma')"
      ],
      "metadata": {
        "id": "qzO-AGRYmPkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy RFC = {metrics.accuracy_score(y_test, y_predict_rfc) * 100} %\")"
      ],
      "metadata": {
        "id": "SAPWm4vUmShP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP"
      ],
      "metadata": {
        "id": "PTo_OiTEkQ35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_mlp = {\n",
        "    'hidden_layer_sizes': [(50, 100, 200, 200, 100, 50)],\n",
        "    'activation': ['logistic', 'relu'],\n",
        "    'max_iter': [100, 300, 500, 800],\n",
        "    'solver': ['sgd', 'adam'],\n",
        "    'learning_rate': ['constant', 'invscaling']\n",
        "}\n",
        "\n",
        "grid_MLP = GridSearchCV(MLPClassifier(), param_grid_mlp, refit=True)\n",
        "grid_MLP.fit(X_train, y_train)\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "-A-DLN0qkR8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLPClassifier().set_params(**grid_MLP.best_params_)\n",
        "mlp.fit(X_train, y_train)\n",
        "y_predict_MLP = mlp.predict(X_test)"
      ],
      "metadata": {
        "id": "47xkon3cQUm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('hiperparámetros MLP:', grid_MLP.best_params_)"
      ],
      "metadata": {
        "id": "vlTDYMM5Qfv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Matriz de confusión MLP\")\n",
        "cm_MLP = confusion_matrix(y_test, y_predict_MLP, normalize=\"all\")\n",
        "cm_display = ConfusionMatrixDisplay(cm_MLP).plot(cmap='magma')"
      ],
      "metadata": {
        "id": "r82rYB5GQisF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy MLP = {metrics.accuracy_score(y_test, y_predict_MLP) * 100} %\")"
      ],
      "metadata": {
        "id": "nSJRs5QpQkpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADABoost"
      ],
      "metadata": {
        "id": "VhCRpDWCkSml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_ada = {\n",
        "    'estimator': [DTC(max_depth=2), DTC(max_depth=10), DTC(max_depth=100)],\n",
        "    'n_estimators': [50, 100, 200, 300],\n",
        "    'learning_rate': [0, 10, 50, 100, 1000],\n",
        "    'algorithm': ['SAMME', 'SAMME.R'],\n",
        "}\n",
        "\n",
        "grid_ada = GridSearchCV(AdaBoostClassifier(), param_grid_ada, refit=True)\n",
        "grid_ada.fit(X_train, y_train)\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "RxrlRWz1m_i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abc = AdaBoostClassifier().set_params(**grid_ada.best_params_)\n",
        "abc.fit(X_train, y_train)\n",
        "y_predict_abc = abc.predict(X_test)"
      ],
      "metadata": {
        "id": "hhMnM8IZkTrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_print(\"Matriz de confusión ABC\")\n",
        "cm_abc = confusion_matrix(y_test, y_predict_abc, normalize=\"all\")\n",
        "cm_display = ConfusionMatrixDisplay(cm_abc).plot(cmap='magma')"
      ],
      "metadata": {
        "id": "D6W5toLNKjc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy ABC = {metrics.accuracy_score(y_test, y_predict_abc) * 100} %\")"
      ],
      "metadata": {
        "id": "PnXXAxnuKk9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost"
      ],
      "metadata": {
        "id": "YtRlMkb1l_d4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid_xgb = {\n",
        "    'loss': ['log_loss', 'deviance', 'exponential'],\n",
        "    'n_estimators': [50, 100, 200, 300],\n",
        "    'learning_rate': [0, 10, 50, 100, 1000],\n",
        "    'criterion': ['friedman_mse', 'squared_error']   \n",
        "}\n",
        "\n",
        "grid_xgb = GridSearchCV(GradientBoostingClassifier(), param_grid_xgb, refit=True)\n",
        "grid_xgb.fit(X_train, y_train)\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "RhJ3Tr72rbq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgbc = GradientBoostingClassifier().set_params(**grid_xgb.best_params_)\n",
        "xgbc.fit(X_train, y_train)\n",
        "y_predict_xgbc = xgbc.predict(X_test)\n",
        "y_predict_xgbc2 = grid_xgb.predict(X_test)"
      ],
      "metadata": {
        "id": "CwbLnsGRrd-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Matriz de confusión XGBC\")\n",
        "cm_xgbc = confusion_matrix(y_test, y_predict_xgbc, normalize=\"all\")\n",
        "cm_display = ConfusionMatrixDisplay(cm_xgbc).plot(cmap='magma')"
      ],
      "metadata": {
        "id": "DWh7oTcSrfqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy XGBC = {metrics.accuracy_score(y_test, y_predict_xgbc) * 100} %\")\n",
        "print(f\"Accuracy XGBC2 = {metrics.accuracy_score(y_test, y_predict_xgbc2) * 100} %\")"
      ],
      "metadata": {
        "id": "bNHWsArbrivN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "name": "Proyecto_IIC2433_Data_Mining.ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}